{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking tensorflow intermediate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1124 11:20:55.229263 140735637529472 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions = 2\n",
    "hidden_size = 16\n",
    "dtype=tf.float64\n",
    "\n",
    "x = tf.Variable(tf.truncated_normal(dtype=dtype, \n",
    "                                    shape=(input_dimensions, hidden_size), mean=0, stddev=0.01), \n",
    "                name='Wr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Wr_1:0' shape=(5, 2) dtype=float64_ref>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00023993  0.0154601   0.00696636  0.00011915  0.00746992  0.00567421\n",
      "  -0.00949571 -0.01017981 -0.01170234  0.00565376  0.0066822   0.00576366\n",
      "  -0.0082944  -0.00743214 -0.01937575  0.01698793]\n",
      " [-0.01174113 -0.0060773   0.00360782 -0.00082508  0.0154051   0.00888502\n",
      "   0.01021685  0.00832186  0.00145435 -0.0091737   0.00928058 -0.01194321\n",
      "  -0.00834974 -0.00044248  0.00384688  0.01040147]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(x.eval()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  print(product.eval()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  print(matrix1.eval()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:  print(matrix2.eval()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a graph.\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# Evaluate the tensor `c`.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a + b \n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(c, feed_dict={a: 5, b:7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implmentation of softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12026164079359143, 0.12038196258525403, 0.19807974640639128, 0.1621739799448004, 0.15181606801133768, 0.12630122257481688, 0.12098537968380825]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample = [0.001, 0.002, 0.5, 0.3, 0.234, 0.05, 0.007]\n",
    "exp_ls = [np.exp(i) for i in sample]\n",
    "sum_exp = sum(exp_ls)\n",
    "result = [i/sum_exp for i in exp_ls]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(y_true, y_hat):\n",
    "    return np.sum(- np.array(y_true) * np.log2(np.array(y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5145731728297583"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropy([1,0,0,0], [0.7, 0.2, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.321928094887362"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropy([1,0,0,0], [0.2,.1,0.5,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.321928094887362"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropy([1,0,0,0], [0.2,.5,0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15200309344504995"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20\n",
    "tokenizer = Tokenizer(num_words=num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = ['if you say yes, I will delightfully agree. If you say no, I will painfully do so.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67 µs, sys: 1e+03 ns, total: 68 µs\n",
      "Wall time: 72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'if': 1,\n",
       " 'you': 2,\n",
       " 'say': 3,\n",
       " 'i': 4,\n",
       " 'will': 5,\n",
       " 'yes': 6,\n",
       " 'delightfully': 7,\n",
       " 'agree': 8,\n",
       " 'no': 9,\n",
       " 'painfully': 10,\n",
       " 'do': 11,\n",
       " 'so': 12}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = ['if you say so', 'I hope you agree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if you say so', 'I hope you agree']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 12], [4, 2, 8]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1_token = tokenizer.texts_to_sequences(sample1)\n",
    "sample1_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2, 3, 12, 4, 5, 11]), list([4, 2, 8])], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sample1_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU implementation in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/gru_layers.png\" alt=\"Flowchart NLP\" style=\"width: 1200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this RNN is simply classifying the message as either good or bad, we only need one output from the last GRU node. The output from the last GRU is vector of 4. This will be converted into one last value by `Dense` layer. \n",
    "\n",
    "It makes sense because we don't need every output from the last GRU from every word, `this`, `is`, etc. We only need the one output after consuming all the words from the sentence. \n",
    "\n",
    "However, if we were to translate words, we need an output from the last GRU node for every single word fed into them. So we need to use `return_sequences` in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100\n",
    "embedding_size = 8\n",
    "max_tokens = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 10, 16)            1200      \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 10, 8)             600       \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 2,761\n",
      "Trainable params: 2,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to calculate the parameters\n",
    "\n",
    "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889 \n",
    "\n",
    "for g \n",
    "- GRU = 3 (memory gate, reset gate, internal state) \n",
    "- LSTM = 4 \n",
    "\n",
    "parameters = `g * [h (h1 + i) + h2]`  where \n",
    "\n",
    "- h1 = previous state \n",
    "- h2 = bias \n",
    "- h = hidden units \n",
    "- i = input \n",
    "\n",
    "example for 1st GRU \n",
    "- input dimension from embedding layer for each word = `(1 x 8)` \n",
    "- hidden units in 1st GRU = `16` \n",
    "- GRU, g = 3 \n",
    "\n",
    "param = `3 * [16 (16 + 8) + 16]` = `3 * [16 * 24 + 16]` = `3 * [384 + 16]` = `3 * 400` = `1200` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.data-blogger.com/2017/08/27/gru-implementation-tensorflow/\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"img/gru.png\" width=\"300\"></p>\n",
    "<p align=\"center\">Figure 1. Gated Recurrent Unit</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"img/gru_equation.png\" width=\"300\"></p>\n",
    "<p align=\"center\">Figure 2. Gated Recurrent Unit</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the GRU node, there are 3 operations for the input vectors. Those operations have weights: `W(z)`, `W(r)` and `W(h)`. Therefore, we need to multiply by `3` which is denoted as `g` in the above calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/gru_node.png\" alt=\"GRU node in detail\" style=\"width: 1200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train_pad = np.array([[13,   11,    6,    3,  93,   19,   12,   10,   67,  10,  21, 2,  12,    9,    6,  40,   27,    4,    1,  42],\n",
    "                       [10,  40,   43,   22,   62,  10,   11,   19,   27,   67,  38, 12,    9,   80,   26,   14,  15,    2, 51, 3]])\n",
    "\n",
    "y_train = np.array([[1], [0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = np.array([[13, 11, 6, 3, 93, 19, 12, 10, 67, 10], \n",
    "                        [21, 2, 12, 9, 6, 40, 27, 4, 1, 42],\n",
    "                       [10, 40, 43, 22, 62, 10, 11, 19, 27, 67],\n",
    "                       [38, 12, 9, 80, 26, 14, 15, 2, 51, 3]])\n",
    "y_train = np.array([[1], [0], [1], [1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 11,  6,  3, 93, 19, 12, 10, 67, 10],\n",
       "       [21,  2, 12,  9,  6, 40, 27,  4,  1, 42],\n",
       "       [10, 40, 43, 22, 62, 10, 11, 19, 27, 67],\n",
       "       [38, 12,  9, 80, 26, 14, 15,  2, 51,  3]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 212ms/sample - loss: 0.6923 - acc: 0.6667 - val_loss: 0.6856 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 11ms/sample - loss: 0.6888 - acc: 0.6667 - val_loss: 0.6783 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 13ms/sample - loss: 0.6852 - acc: 0.6667 - val_loss: 0.6711 - val_acc: 1.0000\n",
      "CPU times: user 3.35 s, sys: 118 ms, total: 3.47 s\n",
      "Wall time: 3.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12a7fc940>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_pad, y_train,\n",
    "          validation_split=0.05, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test1 = np.array([[90, 16, 3, 78, 74, 94, 49, 2, 56, 99, 3, 39, 22, 31, 40, 28, 41, 20, 24, 88],\n",
    "                  [10, 40, 43, 22, 62, 10, 11, 19, 27, 67, 38, 12, 9, 80, 26, 14, 15, 2, 51, 3]])\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90, 90,  3, 78, 74, 94, 49,  2, 56, 99]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = np.array([[90, 90, 3, 78, 74, 94, 49, 2, 56, 99]])\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5088825]], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'layer_embedding_4/embedding_lookup/Identity_1:0' shape=(?, 10, 8) dtype=float32>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the intermediate layers in Keras\n",
    "\n",
    "https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.00057229,  0.03144029, -0.01208645,  0.01250266,\n",
       "          -0.0112159 ,  0.01250733,  0.02347985, -0.04540693],\n",
       "         [-0.00057229,  0.03144029, -0.01208645,  0.01250266,\n",
       "          -0.0112159 ,  0.01250733,  0.02347985, -0.04540693],\n",
       "         [-0.02888888, -0.02501615,  0.01376894,  0.02180013,\n",
       "           0.00112535, -0.03033254, -0.0358508 , -0.00298855],\n",
       "         [ 0.04798928, -0.03607267, -0.04041312,  0.01160529,\n",
       "          -0.02674392, -0.03048762,  0.00823299,  0.04192502],\n",
       "         [-0.01783573,  0.01018466, -0.02773213, -0.04810634,\n",
       "          -0.0474182 ,  0.01849345,  0.0055408 , -0.01327863],\n",
       "         [ 0.02917637,  0.01125299,  0.02330646,  0.02039612,\n",
       "           0.03949693,  0.02127938,  0.03067532, -0.01710946],\n",
       "         [ 0.04990566,  0.0440275 , -0.00158658, -0.00284252,\n",
       "          -0.01484345, -0.04878316, -0.00673587,  0.0132655 ],\n",
       "         [ 0.04800986,  0.01151798,  0.04138615, -0.02686044,\n",
       "          -0.04933664, -0.02193256,  0.03097831, -0.02450117],\n",
       "         [-0.0174017 , -0.03615798,  0.01877761, -0.0472291 ,\n",
       "           0.04493736,  0.04178489,  0.01422301,  0.00873451],\n",
       "         [-0.04499685, -0.023809  ,  0.02432552, -0.01106194,\n",
       "           0.0304847 ,  0.0381094 , -0.02346256,  0.02266133]]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with a Sequential model\n",
    "from keras import backend as K\n",
    "\n",
    "get_1st_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[0].output])\n",
    "get_1st_layer_output([test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st GRU layer output (units=16)\n",
    "\n",
    "Embedding layer emit (10 x 8) for each word.  \n",
    "1st GRU will receive (10 x 8) and will emit (10 x 16)\n",
    "\n",
    "1st word, tokenized as '90' is embedding as `[ 0.02807844,  0.03798428, -0.0355945 , -0.03939711, -0.01135957, -0.02653174,  0.04787086,  0.00446305]`. Since the 2nd word is also the same `90`, its embedding layer output is the same as the 1st one. \n",
    "\n",
    "This embedding output is fed into 1st GRU node, which will emit 16 states (or units). Since there are 10 words in 1st sample (labeled test2), the output will be `(10 x 16)`. Now if you look at the result, the first and second output are different. The first one is `[-7.39353709e-03, -2.45588785e-03, ...]`, and 2nd one is `[-1.13133024e-02, -2.58720666e-03, ...]`. But they are for the same word, tokenized as `90`. Shouldn't they be the same? \n",
    "\n",
    "The reason they're different is because GRU node state changes, depending on the input and the previous output. It has a memory state. So after receiving the first word `90`, it emits `[-7.39353709e-03, -2.45588785e-03, ...]`, which becomes internal state or memory state for next word. When the next word comes, albeit it's the same `90`, with its internal matrix product, the output now becomes different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-7.39353709e-03, -2.45588785e-03,  9.36997775e-03,\n",
       "           5.98293089e-04,  4.61337762e-03, -1.39055622e-03,\n",
       "          -5.94481872e-03,  6.91419747e-03,  2.37650634e-03,\n",
       "           1.02202231e-02,  9.74046253e-03, -1.99844595e-03,\n",
       "           6.11742772e-03, -3.99018964e-03,  9.21347458e-03,\n",
       "           4.57908201e-04],\n",
       "         [-1.13133024e-02, -2.58720666e-03,  1.37651609e-02,\n",
       "           5.02947369e-05,  6.80340594e-03, -2.08873162e-03,\n",
       "          -8.64002854e-03,  1.05433632e-02,  3.94365098e-03,\n",
       "           1.54888202e-02,  1.60077885e-02, -3.52106686e-03,\n",
       "           8.50645918e-03, -4.25248407e-03,  1.53070539e-02,\n",
       "           1.21246769e-04],\n",
       "         [-5.64358057e-03, -8.63628741e-03,  6.53780019e-03,\n",
       "          -1.63866580e-02,  8.16475973e-03, -2.05401350e-02,\n",
       "          -1.05933463e-02,  9.65292007e-03,  7.13120215e-03,\n",
       "           1.83349773e-02, -3.01691052e-03,  2.29730085e-03,\n",
       "          -3.47107695e-03,  1.30173983e-04,  1.72474934e-03,\n",
       "           2.92117568e-03],\n",
       "         [-5.72708948e-03, -1.61986854e-02,  7.50042871e-03,\n",
       "          -8.50571506e-03,  3.44328070e-03, -2.67582666e-02,\n",
       "           1.48944138e-03,  1.03609227e-02,  9.67954751e-03,\n",
       "           1.00970287e-02,  1.95855042e-04, -3.70523008e-03,\n",
       "          -1.44140073e-03,  1.60807162e-04,  1.34845646e-02,\n",
       "           6.39068603e-04],\n",
       "         [ 8.60120449e-03, -1.31863020e-02,  6.38704095e-03,\n",
       "          -1.21501656e-02, -9.98881459e-03, -2.51501836e-02,\n",
       "           6.03665318e-03, -8.93243402e-03,  1.35110505e-03,\n",
       "           1.19140819e-02, -2.50325631e-03,  1.01387186e-03,\n",
       "          -5.68871805e-03,  4.98764310e-03,  6.12201169e-03,\n",
       "           4.92288684e-03],\n",
       "         [ 1.78038757e-02, -3.08098109e-03, -1.07638547e-02,\n",
       "          -9.53154452e-03, -1.16245551e-02, -2.77590472e-03,\n",
       "          -7.23815989e-03,  2.10842816e-03,  5.00700809e-03,\n",
       "          -1.25544937e-03, -1.41769191e-02, -8.99251085e-03,\n",
       "           8.56408477e-03,  1.13840885e-02, -1.56579595e-02,\n",
       "          -1.00905821e-02],\n",
       "         [ 5.91803063e-03, -7.74949044e-03, -7.28370715e-03,\n",
       "          -9.68078990e-03, -8.51621572e-03, -7.58539140e-03,\n",
       "          -6.80582877e-03,  1.16137825e-02,  3.81169119e-03,\n",
       "           1.03599473e-03, -9.41870548e-03, -1.38190966e-02,\n",
       "           5.00420202e-03,  9.12834797e-03, -8.91935453e-03,\n",
       "          -1.00251865e-02],\n",
       "         [ 2.97486410e-03, -1.11047896e-02, -4.40892950e-03,\n",
       "          -2.10240092e-02, -6.49655331e-03, -1.45883430e-02,\n",
       "          -9.15643573e-03,  9.42711812e-03,  7.81748071e-03,\n",
       "           5.77712152e-03, -1.57983098e-02, -8.30990076e-03,\n",
       "          -1.67315220e-03,  1.02576409e-02, -1.30689684e-02,\n",
       "          -3.79241072e-03],\n",
       "         [-1.36881750e-02, -1.34492302e-02, -8.95101577e-03,\n",
       "          -2.13694982e-02,  1.13625415e-02, -1.67622492e-02,\n",
       "          -9.27701406e-03,  3.17325443e-02,  1.72328353e-02,\n",
       "          -6.18864875e-03, -1.29552595e-02, -1.85047872e-02,\n",
       "          -4.46363399e-03,  7.63491914e-03, -2.00708304e-03,\n",
       "          -1.31881367e-02],\n",
       "         [-1.59804672e-02, -8.11747555e-03,  3.88293108e-03,\n",
       "          -1.19633274e-02,  7.07901688e-03, -2.72353180e-03,\n",
       "          -4.27305233e-03,  2.59614959e-02,  1.79901980e-02,\n",
       "          -5.43719158e-03,  4.37634625e-03, -2.28914842e-02,\n",
       "           1.73616479e-03,  3.52108828e-03,  1.01068635e-02,\n",
       "          -1.01059517e-02]]], dtype=float32)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2nd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])\n",
    "get_2nd_layer_output([test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.00130251, -0.00374961, -0.0031796 , -0.0049633 ,\n",
       "           0.00036867,  0.00457511, -0.00612586, -0.00412154],\n",
       "         [-0.00407208, -0.00681909, -0.00433862, -0.00891543,\n",
       "          -0.00251949,  0.00876667, -0.01149588, -0.00704769],\n",
       "         [ 0.00243492, -0.00821556,  0.00203187, -0.01002471,\n",
       "          -0.00347194,  0.01034054, -0.01529316, -0.01056274],\n",
       "         [ 0.00994521, -0.00717895,  0.00555692, -0.0062808 ,\n",
       "          -0.00204963,  0.01307923, -0.01548386, -0.01110561],\n",
       "         [ 0.01507948, -0.00959584,  0.00468181, -0.00271715,\n",
       "           0.00095033,  0.00689437, -0.01090126, -0.01092082],\n",
       "         [ 0.01567085, -0.01425946, -0.00503693, -0.00313515,\n",
       "           0.0013425 ,  0.00697276, -0.010996  , -0.01877937],\n",
       "         [ 0.01722615, -0.01498277, -0.0072018 , -0.00277071,\n",
       "          -0.0004091 ,  0.0097972 , -0.01463094, -0.02147865],\n",
       "         [ 0.02065217, -0.01545376, -0.00434624, -0.00325283,\n",
       "          -0.0031377 ,  0.0124184 , -0.0153431 , -0.02298888],\n",
       "         [ 0.02738774, -0.00974723,  0.00225205, -0.00379394,\n",
       "          -0.00384877,  0.02369755, -0.0197054 , -0.02259599],\n",
       "         [ 0.02508083, -0.00855413, -0.00010214, -0.00397063,\n",
       "          -0.00536581,  0.0293884 , -0.01899088, -0.01999183]]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[2].output])\n",
    "get_3rd_layer_output([test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.05640356, -0.02059804, -0.00316206,  0.01036271]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[3].output])\n",
    "get_3rd_layer_output([test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.5165275]], dtype=float32)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_4th_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[4].output])\n",
    "get_4th_layer_output([test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5165275]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50\n",
    "embedding_size = 10\n",
    "state_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None, ), name='encoder_input')\n",
    "encoder_embedding = Embedding(input_dim=num_words,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='encoder_embedding')\n",
    "encoder_gru1 = GRU(state_size, name='encoder_gru1',\n",
    "                   return_sequences=True)\n",
    "encoder_gru2 = GRU(state_size, name='encoder_gru2',\n",
    "                   return_sequences=True)\n",
    "encoder_gru3 = GRU(state_size, name='encoder_gru3',\n",
    "                   return_sequences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_encoder():\n",
    "    # Start the neural network with its input-layer.\n",
    "    net = encoder_input\n",
    "    \n",
    "    # Connect the embedding-layer.\n",
    "    net = encoder_embedding(net)\n",
    "\n",
    "    # Connect all the GRU-layers.\n",
    "    net = encoder_gru1(net)\n",
    "    net = encoder_gru2(net)\n",
    "    net = encoder_gru3(net)\n",
    "\n",
    "    # This is the output of the encoder.\n",
    "    encoder_output = net\n",
    "    \n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = connect_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state = Input(shape=(state_size,),\n",
    "                              name='decoder_initial_state')\n",
    "decoder_input = Input(shape=(None, ), name='decoder_input')\n",
    "decoder_embedding = Embedding(input_dim=num_words,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='decoder_embedding')\n",
    "decoder_gru1 = GRU(state_size, name='decoder_gru1',\n",
    "                   return_sequences=True)\n",
    "decoder_gru2 = GRU(state_size, name='decoder_gru2',\n",
    "                   return_sequences=True)\n",
    "decoder_gru3 = GRU(state_size, name='decoder_gru3',\n",
    "                   return_sequences=True)\n",
    "decoder_dense = Dense(num_words,\n",
    "                      activation='linear',\n",
    "                      name='decoder_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_decoder(initial_state):\n",
    "    # Start the decoder-network with its input-layer.\n",
    "    net = decoder_input\n",
    "\n",
    "    # Connect the embedding-layer.\n",
    "    net = decoder_embedding(net)\n",
    "    \n",
    "    # Connect all the GRU-layers.\n",
    "    net = decoder_gru1(net, initial_state=initial_state)\n",
    "    net = decoder_gru2(net, initial_state=initial_state)\n",
    "    net = decoder_gru3(net, initial_state=initial_state)\n",
    "\n",
    "    # Connect the final dense layer that converts to\n",
    "    # one-hot encoded arrays.\n",
    "    decoder_output = decoder_dense(net)\n",
    "    \n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(initial_state=encoder_output)\n",
    "\n",
    "model_train = Model(inputs=[encoder_input, decoder_input],\n",
    "                    outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = Model(inputs=[encoder_input],\n",
    "                      outputs=[encoder_output])\n",
    "decoder_output = connect_decoder(initial_state=decoder_initial_state)\n",
    "\n",
    "model_decoder = Model(inputs=[decoder_input, decoder_initial_state],\n",
    "                      outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "decoder_target = tf.placeholder(dtype='int32', shape=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train.compile(optimizer=optimizer,\n",
    "                    loss=sparse_cross_entropy,\n",
    "                    target_tensors=[decoder_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = '21_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.array([[13, 11, 6, 3, 3, 19, 12, 10, 27, 10], \n",
    "                               [21, 2, 12, 9, 6, 40, 27, 4, 1, 42]])\n",
    "decoder_input_data = np.array([[2, 40, 19, 43, 26, 20, 18, 1, 45, 3],\n",
    "                               [2, 40, 43, 22, 2, 10, 11, 19, 27, 3]])\n",
    "decoder_output_data = np.array([[40, 19, 43, 26, 20, 18, 1, 45, 3, 0],\n",
    "                               [40, 43, 22, 2, 10, 11, 19, 27, 3, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \\\n",
    "{\n",
    "    'encoder_input': encoder_input_data,\n",
    "    'decoder_input': decoder_input_data\n",
    "}\n",
    "y_data = \\\n",
    "{\n",
    "    'decoder_output': decoder_output_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 928ms/sample - loss: 3.9103\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 28ms/sample - loss: 3.9014\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 31ms/sample - loss: 3.8943\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 35ms/sample - loss: 3.8877\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 31ms/sample - loss: 3.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13887a898>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit(x=x_data,\n",
    "                y=y_data,\n",
    "                batch_size=512,\n",
    "                epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, None, 10)     1000        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru1 (GRU)              (None, None, 8)      456         encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru2 (GRU)              (None, None, 8)      408         encoder_gru1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 10)     500         decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru3 (GRU)              (None, 8)            408         encoder_gru2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru1 (GRU)              (None, None, 8)      456         decoder_embedding[0][0]          \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru2 (GRU)              (None, None, 8)      408         decoder_gru1[0][0]               \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru3 (GRU)              (None, None, 8)      408         decoder_gru2[0][0]               \n",
      "                                                                 encoder_gru3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, None, 50)     450         decoder_gru3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,494\n",
      "Trainable params: 4,494\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking intermediate layers in Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_e = np.array([[16, 12, 46, 33, 13], \n",
    "                  [23, 23, 2, 49, 6]])\n",
    "test1_d = np.array([[2, 2, 4, 4, 3], \n",
    "                  [2, 35, 24, 9, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'encoder_input_1:0' shape=(?, ?) dtype=float32>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 5.83190098e-02,  1.65246651e-02, -3.11908592e-03,\n",
       "           1.42389992e-02, -2.12707855e-02, -2.98207030e-02,\n",
       "          -5.57734743e-02,  2.73377523e-02,  8.26421287e-03,\n",
       "          -3.68149169e-02,  3.41209173e-02,  3.29646356e-02,\n",
       "          -1.52627639e-02, -1.78109817e-02, -5.65267913e-02,\n",
       "           1.61449797e-03, -4.28009592e-02,  1.47205507e-02,\n",
       "          -2.68751103e-03,  3.80825922e-02, -2.41071209e-02,\n",
       "           2.59800889e-02,  3.77022363e-02, -1.52681768e-02,\n",
       "           1.92913562e-02, -1.62147917e-02,  5.15831821e-03,\n",
       "          -8.37580767e-03, -5.91894798e-02,  1.57503858e-02,\n",
       "          -1.08616799e-02, -4.69888747e-02, -6.07327931e-02,\n",
       "          -2.57650092e-02, -8.72816052e-03, -3.34480964e-02,\n",
       "           1.23722367e-02, -5.75172855e-03,  1.21681727e-02,\n",
       "          -1.78278591e-02,  6.06575832e-02, -1.36935767e-02,\n",
       "          -3.03729484e-03,  5.86389676e-02, -4.02520709e-02,\n",
       "          -3.35508119e-03,  3.95788774e-02, -3.69283408e-02,\n",
       "           2.17085797e-03, -5.61751537e-02],\n",
       "         [ 4.41736095e-02,  2.29820199e-02,  3.58209154e-03,\n",
       "           7.18335435e-03, -1.33370608e-02, -1.01687033e-02,\n",
       "          -4.95574698e-02,  9.10364371e-03,  3.63412965e-03,\n",
       "          -3.44929993e-02,  3.78558040e-02,  2.76581310e-02,\n",
       "          -1.21806460e-02, -1.85958482e-02, -4.51025330e-02,\n",
       "          -9.93953459e-03, -4.28895280e-02,  8.45437869e-04,\n",
       "           1.44840702e-02,  4.43660617e-02, -1.76030491e-03,\n",
       "           4.96447459e-03,  2.16160379e-02, -1.69411562e-02,\n",
       "           1.09862331e-02, -3.87201412e-03,  3.72253172e-03,\n",
       "          -1.08664250e-02, -5.34320585e-02,  6.80728257e-03,\n",
       "          -1.10657178e-02, -3.67846191e-02, -4.32696752e-02,\n",
       "          -2.18303353e-02, -1.11047626e-02, -3.61894816e-02,\n",
       "          -9.67182219e-03, -7.73445051e-03,  1.77844390e-02,\n",
       "          -1.40003311e-02,  5.43169528e-02, -6.66175922e-03,\n",
       "          -5.13514457e-03,  4.78734262e-02, -3.76504026e-02,\n",
       "           1.67317186e-02,  2.67142300e-02, -3.11927479e-02,\n",
       "           1.44732343e-02, -5.25462106e-02],\n",
       "         [ 3.35838944e-02,  2.52843909e-02,  7.01228622e-03,\n",
       "           5.43567073e-03, -1.18793380e-02, -2.37654895e-04,\n",
       "          -4.37944531e-02, -3.12203867e-03, -3.60447913e-04,\n",
       "          -2.95801591e-02,  3.44311781e-02,  2.33362131e-02,\n",
       "          -9.66418907e-03, -1.98385268e-02, -3.61863896e-02,\n",
       "          -1.22522190e-02, -3.97799909e-02, -5.73951285e-03,\n",
       "           2.43391152e-02,  4.54152077e-02,  8.41140840e-03,\n",
       "          -6.03883481e-03,  1.36715760e-02, -1.80320777e-02,\n",
       "           4.41391207e-03,  1.00358948e-03,  5.49708819e-03,\n",
       "          -9.42169782e-03, -4.52502184e-02, -4.44787554e-04,\n",
       "          -1.14096338e-02, -2.90232077e-02, -3.21777612e-02,\n",
       "          -2.07433403e-02, -1.30552407e-02, -3.43581587e-02,\n",
       "          -2.04387605e-02, -8.95178877e-03,  1.62741300e-02,\n",
       "          -1.17769446e-02,  4.53387387e-02, -5.71008679e-03,\n",
       "          -5.70507860e-03,  3.99242677e-02, -3.39628793e-02,\n",
       "           2.43228935e-02,  1.79611314e-02, -2.65020523e-02,\n",
       "           1.98569335e-02, -4.83011566e-02],\n",
       "         [ 2.73965821e-02,  2.54857838e-02,  8.50033294e-03,\n",
       "           6.02407195e-03, -1.26143238e-02,  3.48029472e-03,\n",
       "          -3.95484343e-02, -1.02765178e-02, -3.30999307e-03,\n",
       "          -2.57830657e-02,  2.97213364e-02,  1.98572632e-02,\n",
       "          -8.59373529e-03, -2.07030512e-02, -3.02306935e-02,\n",
       "          -1.17075602e-02, -3.68055776e-02, -9.36941989e-03,\n",
       "           2.96253767e-02,  4.34987471e-02,  1.18147777e-02,\n",
       "          -1.06576830e-02,  1.03045609e-02, -1.91919263e-02,\n",
       "          -8.02595168e-05,  1.36951637e-03,  8.12111888e-03,\n",
       "          -6.47434499e-03, -3.87016498e-02, -5.31986030e-03,\n",
       "          -1.20243803e-02, -2.38884203e-02, -2.60439813e-02,\n",
       "          -2.05279347e-02, -1.43785896e-02, -3.09671573e-02,\n",
       "          -2.50009336e-02, -9.05496627e-03,  1.24992859e-02,\n",
       "          -9.78640374e-03,  3.81312147e-02, -6.51315646e-03,\n",
       "          -5.77753037e-03,  3.44868042e-02, -3.05981822e-02,\n",
       "           2.61880830e-02,  1.27542987e-02, -2.35717148e-02,\n",
       "           2.12167948e-02, -4.50468659e-02],\n",
       "         [ 2.53620259e-02,  2.34948881e-02,  8.50100815e-03,\n",
       "           9.05684847e-03, -1.47490967e-02,  1.78806111e-03,\n",
       "          -3.62457633e-02, -1.34117091e-02, -5.88095747e-03,\n",
       "          -2.37257667e-02,  2.36734226e-02,  1.64150670e-02,\n",
       "          -1.00001087e-02, -2.07375959e-02, -2.60930564e-02,\n",
       "          -9.72303376e-03, -3.41988578e-02, -1.23505909e-02,\n",
       "           3.13847065e-02,  3.74274887e-02,  9.53007117e-03,\n",
       "          -9.95257590e-03,  1.00501534e-02, -2.14403495e-02,\n",
       "          -3.53644509e-03, -3.16683669e-03,  1.22227669e-02,\n",
       "          -1.05842762e-03, -3.32506187e-02, -8.69762246e-03,\n",
       "          -1.35771446e-02, -2.06420142e-02, -2.35139914e-02,\n",
       "          -2.02461481e-02, -1.57151762e-02, -2.56047025e-02,\n",
       "          -2.48699319e-02, -7.81458430e-03,  6.01930916e-03,\n",
       "          -6.58402452e-03,  3.19638401e-02, -8.11672118e-03,\n",
       "          -5.16241696e-03,  3.01654041e-02, -2.72026919e-02,\n",
       "           2.37231925e-02,  1.02379099e-02, -2.22187005e-02,\n",
       "           1.85883157e-02, -4.21233848e-02]],\n",
       " \n",
       "        [[ 5.77155463e-02,  1.78720821e-02, -2.66861822e-03,\n",
       "           1.36916004e-02, -2.05385350e-02, -2.91827992e-02,\n",
       "          -5.35006002e-02,  2.19488554e-02,  6.50705490e-03,\n",
       "          -3.58048305e-02,  3.20331529e-02,  3.06281298e-02,\n",
       "          -1.43218124e-02, -1.64858438e-02, -5.38295880e-02,\n",
       "           1.10040419e-03, -3.97850908e-02,  1.26030007e-02,\n",
       "          -6.99648634e-04,  3.59755717e-02, -2.25501768e-02,\n",
       "           2.47345567e-02,  3.64982933e-02, -1.54473819e-02,\n",
       "           1.75120253e-02, -1.61967035e-02,  7.88513757e-03,\n",
       "          -4.77726012e-03, -5.68526760e-02,  1.33550409e-02,\n",
       "          -1.06680626e-02, -4.21450064e-02, -5.59396259e-02,\n",
       "          -2.48763748e-02, -9.62058827e-03, -2.95517333e-02,\n",
       "           1.15615819e-02, -5.12585090e-03,  1.03733409e-02,\n",
       "          -1.59788746e-02,  5.90002760e-02, -1.30419638e-02,\n",
       "          -2.60065310e-03,  5.73792346e-02, -3.81350368e-02,\n",
       "          -2.83650123e-03,  3.90980989e-02, -3.75944562e-02,\n",
       "           2.60802079e-03, -5.43037094e-02],\n",
       "         [ 4.61212881e-02,  2.27039382e-02,  2.88949814e-03,\n",
       "           8.26992840e-03, -1.40274419e-02, -1.31032579e-02,\n",
       "          -4.81220335e-02,  6.57120813e-03,  2.41539627e-03,\n",
       "          -3.50410417e-02,  3.48470397e-02,  2.55370513e-02,\n",
       "          -1.24244243e-02, -1.70403812e-02, -4.34992127e-02,\n",
       "          -9.16279107e-03, -4.06393670e-02, -6.07643276e-04,\n",
       "           1.47433346e-02,  3.98395769e-02, -4.40917164e-03,\n",
       "           7.46764801e-03,  2.29758546e-02, -1.75439734e-02,\n",
       "           9.71241295e-03, -7.00351875e-03,  7.21058995e-03,\n",
       "          -6.17186818e-03, -5.18906377e-02,  5.30275516e-03,\n",
       "          -1.14922104e-02, -3.34416106e-02, -4.14773002e-02,\n",
       "          -2.11772118e-02, -1.18490662e-02, -3.11411358e-02,\n",
       "          -7.43469130e-03, -6.08929526e-03,  1.43182147e-02,\n",
       "          -1.15788160e-02,  5.37574850e-02, -7.13077933e-03,\n",
       "          -4.68302052e-03,  4.73043509e-02, -3.53494100e-02,\n",
       "           1.42620318e-02,  2.79803816e-02, -3.27715650e-02,\n",
       "           1.23669775e-02, -5.14077209e-02],\n",
       "         [ 3.80810350e-02,  2.44373735e-02,  5.36592677e-03,\n",
       "           7.47971470e-03, -1.31063368e-02, -6.17655087e-03,\n",
       "          -4.29890528e-02, -4.43880260e-03, -1.62995979e-03,\n",
       "          -3.17919292e-02,  3.12318392e-02,  2.04753522e-02,\n",
       "          -1.09952707e-02, -1.80472787e-02, -3.54572162e-02,\n",
       "          -1.14962170e-02, -3.82648855e-02, -7.76679721e-03,\n",
       "           2.41217241e-02,  3.85529548e-02,  2.87957909e-03,\n",
       "          -8.54181126e-04,  1.65731162e-02, -1.95235517e-02,\n",
       "           3.68534867e-03, -4.93935356e-03,  9.72928386e-03,\n",
       "          -3.25586088e-03, -4.50677648e-02, -1.26187410e-03,\n",
       "          -1.21876262e-02, -2.60690078e-02, -3.22902724e-02,\n",
       "          -2.00467296e-02, -1.35250725e-02, -2.77253184e-02,\n",
       "          -1.65104419e-02, -5.92415454e-03,  1.16943885e-02,\n",
       "          -8.19573924e-03,  4.64614667e-02, -6.03397423e-03,\n",
       "          -5.50290523e-03,  3.98251340e-02, -3.11135072e-02,\n",
       "           2.05382295e-02,  2.07156446e-02, -2.93068625e-02,\n",
       "           1.62781999e-02, -4.80108745e-02],\n",
       "         [ 3.46635208e-02,  2.36483421e-02,  5.55567304e-03,\n",
       "           9.67920478e-03, -1.44141410e-02, -6.88339211e-03,\n",
       "          -3.82334329e-02, -1.12261344e-02, -5.63915865e-03,\n",
       "          -2.96694487e-02,  2.50292532e-02,  1.49729010e-02,\n",
       "          -1.17015187e-02, -1.81583539e-02, -2.93130502e-02,\n",
       "          -1.12142097e-02, -3.49716097e-02, -1.31155942e-02,\n",
       "           2.88291704e-02,  3.15399840e-02,  2.55405903e-03,\n",
       "          -2.39613652e-03,  1.46088041e-02, -2.22046655e-02,\n",
       "          -9.33771953e-04, -9.20044817e-03,  1.40892975e-02,\n",
       "           3.30180908e-03, -3.88738476e-02, -6.04847539e-03,\n",
       "          -1.32843070e-02, -2.00553760e-02, -2.72854306e-02,\n",
       "          -1.90907419e-02, -1.46758128e-02, -2.06729658e-02,\n",
       "          -1.88528188e-02, -4.07313416e-03,  5.07888943e-03,\n",
       "          -4.04478330e-03,  4.00914252e-02, -6.30816864e-03,\n",
       "          -5.97461313e-03,  3.36332917e-02, -2.56791934e-02,\n",
       "           2.06583031e-02,  1.64471641e-02, -2.76778955e-02,\n",
       "           1.48232775e-02, -4.41640168e-02],\n",
       "         [ 3.52392830e-02,  2.16909759e-02,  4.76978347e-03,\n",
       "           1.30759645e-02, -1.66005138e-02, -1.09340306e-02,\n",
       "          -3.55987623e-02, -1.40620209e-02, -8.27448443e-03,\n",
       "          -2.96631940e-02,  1.93341747e-02,  1.06495526e-02,\n",
       "          -1.38015077e-02, -1.77679658e-02, -2.58731991e-02,\n",
       "          -9.89548862e-03, -3.32009867e-02, -1.71528962e-02,\n",
       "           3.09012122e-02,  2.36100592e-02, -1.78581476e-03,\n",
       "           4.39500436e-04,  1.55271078e-02, -2.52038985e-02,\n",
       "          -3.95229040e-03, -1.58599336e-02,  1.89372394e-02,\n",
       "           1.00823622e-02, -3.51383574e-02, -8.95299669e-03,\n",
       "          -1.50579829e-02, -1.65782180e-02, -2.59722359e-02,\n",
       "          -1.85939670e-02, -1.57827698e-02, -1.37034841e-02,\n",
       "          -1.77190360e-02, -1.34617276e-03, -1.88685395e-03,\n",
       "           5.05432487e-04,  3.62671427e-02, -7.35490676e-03,\n",
       "          -5.74731268e-03,  2.98974700e-02, -2.17163190e-02,\n",
       "           1.77333355e-02,  1.55319925e-02, -2.78396290e-02,\n",
       "           1.14274556e-02, -4.23644595e-02]]], dtype=float32)]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with a Sequential model\n",
    "from keras import backend as K\n",
    "\n",
    "get_1st_layer_output = K.function(inputs  = [model_train.layers[0].input, model_train.layers[3].input],\n",
    "                                  outputs = [model_train.layers[10].output])\n",
    "get_1st_layer_output([test1_e, test1_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.65495786, 0.88441492, 0.07064226, 0.12934237, 0.06340601],\n",
       "        [0.11318139, 0.24185687, 0.16992654, 0.01078665, 0.61953245],\n",
       "        [0.48669977, 0.72875375, 0.48223012, 0.02217202, 0.8067884 ]],\n",
       "\n",
       "       [[0.75088541, 0.5426623 , 0.33015992, 0.12262951, 0.07843957],\n",
       "        [0.56402264, 0.30867622, 0.07711186, 0.28058797, 0.23841429],\n",
       "        [0.85780687, 0.1998348 , 0.0728362 , 0.6682692 , 0.35341616]]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true = np.array([[1, 2, 3], [4, 5, 1]])\n",
    "test_pred = np.random.random_sample(size=(2, 3, 5))\n",
    "test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 5)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_3:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_cross_entropy(test_true, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My explanation on sparse_cross_entropy\n",
    "\n",
    "sparse vectors are used to save memory instead of encoding all the zero in the vectors. For example, let's say there is a corpus of `['apple', 'orange', 'is', 'fruit', 'sweet', 'ssss', 'eeee']` words. There are 7 words in the corpus. If we're predicting `orange` word in our model, and using one hot encoding, it will be a vector of `[0, 1, 0, 0, 0, 0, 0]`. The `1` at the 2nd index indicates the word `orange`. For a small corpus, it's manageable. But if the corpus becomes very huge like `10,000` or `20,000`, it's a waste of memory. So instead of using a complete vector format, sparse vector helps to save the memory. The sparse vector in the above example would be : `[1]`. In Python, the first index is considered as `0`. So the word `orange` in sparse vector is just `[1]`. We save an ample amount of memory. \n",
    "\n",
    "The same logic applies in `tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)`. The labels `y_true` is a sparse vector. the logits or predicted values are with actual values. Let's say we're predicting the description `apple is fruit` in encoder-decoder model. The input for the decoder is `ssss apple is fruit eeee` and decoder output is `apple is fruit eeee`. It looks like this. \n",
    "\n",
    "```\n",
    "       encoder input\n",
    "           |\n",
    "ssss  [5] ---> apple [0]\n",
    "apple [0] ---> is    [2]\n",
    "is    [2] ---> fruit [3]\n",
    "fruit [3] ---> eeee  [6]\n",
    "```\n",
    "\n",
    "This is very simple illustration of encoder-decoder model with arbitrary tokenization of each word. You can see that the first word `ssss[5]` is converted to the word `apple` whose token is `0`. How do we convert the value from `5` to `0`. Of course, there are many layers, embedding layers, GRU to execute the operation. \n",
    "\n",
    "### Loss function \n",
    "\n",
    "Imagine if our model predicts `is orange fruit` instead of `apple is fruit`, we want to punish our model by cost. How do we implement a loss function? Cross entropy is a mathematical operation that involves taking the log on the predicted value. The label is always in the form of one hot. Either it's a complete one hot vector or sparse vector is just for saving memory space. But always remember, label is always in one hot vector form. So first thing you need to check is log function. How does it look alike? \n",
    "\n",
    "<img src=\"img/log_graph.png\" alt=\"Log graph\" style=\"width: 300px;\"/>\n",
    "\n",
    "You can see that when the x value or predicted value is `0`, the penalty is very huge in the negative y value. When the x value is `1`, which is correctly predicted, the penalty is zero `0`. Since our predicted value lies between `0` and `1` on x-axis, you can ignore the log graph in the 1st quadrant, which is when the x-value is more than 1. Now that we understand the log function, we can simply imagine in the following scenario. \n",
    "\n",
    "Let's say the true value is `1`, and our predicted value is `1`, the cost should be `0`. So taking our predicted value of `1` by log (either log10 or log2), it will become `0`. When the `log2(x=1) = 0` is multiplied with the true value `1`, it produces `0`. The cost is `0`. This is a basic concept of loss function in cross entropy. So imagine if our predicted value is either `0.1` or `0.7`, which value will have more penalty? It's straightforward. The predicted value of `0.1` will have more penalty because it's much farther away from the true value of `1`, and taking `log2(0.1) = -3.3219` than `log2(0.7) = -0.5146`. If the negative sign bothers you, you can convert it to positive sign by multiplying with `-1`. \n",
    "\n",
    "Now let's go back to our example. \n",
    "\n",
    "```\n",
    "       encoder input\n",
    "           |\n",
    "ssss  [5] ---> apple [0], predicted -> is     [2]\n",
    "apple [0] ---> is    [2], predicted -> orange [1]\n",
    "is    [2] ---> fruit [3], predicted -> fruit  [3]\n",
    "fruit [3] ---> eeee  [6], predicted -> eeee   [6] \n",
    "```\n",
    "\n",
    "So the first word true label is supposed to be apple, but it is predicted by our model to be `is[2]`. Let's dive into loss function in detail. Suppose our model has embedding layer with 7 words with 3 features, GRU with 5 units, the true label for the entire sentence: `apple is fruit` is `np.array([[0, 2, 3]])`. The shape of true label is `(1, 3)`, `1` --> there is only one sample in this batch. `3` is the length of the sequence or length of the description. Since label is `apple is fruit`, there are 3 words. Look at the number carefully, `0, 2, 3`. They represents the index of the true labels. It's in sparse vector form. That's why it's a bit confusing here. If it were to be a complete vector form, it will look like this. \n",
    "\n",
    "```\n",
    "corpus in embedding layer \n",
    "['apple', 'orange', 'is', 'fruit', 'sweet', 'ssss', 'eeee']\n",
    "\n",
    "apple --> [1, 0, 0, 0, 0, 0, 0] \n",
    "is    --> [0, 0, 1, 0, 0, 0, 0]\n",
    "fruit --> [0, 0, 0, 1, 0, 0, 0]\n",
    "```\n",
    "\n",
    "Instead of all those zeros to represent `apple is fruit`, just a sparse vector format of `[0, 2, 3]`, it saves a space. But it can be confusing sometimes. \n",
    "\n",
    "Now let's look at our predicted value `is apple fruit`. Of course we didn't know our predicted words beforehand. All we receive is the floating points value, which we need to convert into integer so that we can then map into our corpus index, to translate into texts. \n",
    "\n",
    "```\n",
    "                last output from the Dense layer            softmax \n",
    "1st word = [0.01, 0.002, 0.5, 0.3, 0.234, 0.05, 0.07] = [0.1203, 0.1193, 0.1963, 0.1607, 0.1505, 0.1252, 0.1277]\n",
    "2nd word = [0.8, 0.01, 0.03, 0.001, 0.3, 0.2, 0.06]   = [0.2501, 0.1135, 0.1158, 0.1125, 0.1517, 0.1372, 0.1193]\n",
    "3rd word = [0.05, 0.1, 0.07, 0.9, 0.2, 0.08, 0.001]   = [0.1169, 0.1229, 0.1192, 0.2735, 0.1358, 0.1204, 0.1112]\n",
    "```\n",
    "\n",
    "From the last output from the Dense layer, we convert them into softmax. We then take the log2 just to show you how it's slowly changing the value. \n",
    "\n",
    "Let's just take the 1st word for example. \n",
    "\n",
    "```\n",
    "based on the corpus\n",
    "\n",
    "['apple', 'orange', 'is' , 'fruit', 'sweet', 'ssss', 'eeee'] \n",
    "[0.1203,  0.1193 , 0.1963, 0.1607 , 0.1505 , 0.1252, 0.1277]\n",
    "```\n",
    "We can see that the highest value in softmax `0.1963` is the index for the word `is`. But the true value is `apple`, which is the first index. We can see that the cost will be huge because our model is predicting a wrong word. \n",
    "\n",
    "Cross Entropy in detail \n",
    "https://github.com/datasci-w266/2019-summer-assignment-kckenneth/blob/a1-submit/assignment/a1/information_theory.ipynb\n",
    "\n",
    "```\n",
    "def CrossEntropy(y_true, y_hat):\n",
    "    return np.sum(- np.array(y_true) * np.log2(np.array(y_hat)))\n",
    "```\n",
    "\n",
    "CrossEntropy generate a penalty of `3.0553` for our wrong predicting. Let's jump to 3rd word `fruit`, where we predict correctly. For 3rd word, the cost is `1.8704`. The cost becomes very low when we predict correctly. \n",
    "\n",
    "That's the idea of sparse_cross_entropy. \n",
    "\n",
    "You might wonder why the cost is not zero because we're predicting correctly. Honestly, I'm just implementing what the cost will look like with a small sample set. I don't know the exact mechanism behind the cross entropy. I thought of converting the softmax value into just `0 and 1` only. Like any maximum value will be given `1` and others as `0`. But this will create `log2(0) = inf` problem. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11688265731814443, 0.12287535930618881, 0.11924384362185905, 0.27346414123914103, 0.13579827365329575, 0.12044226417401714, 0.11129346068735398]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample = [0.05, 0.1, 0.07, 0.9, 0.2, 0.08, 0.001]\n",
    "exp_ls = [np.exp(i) for i in sample]\n",
    "sum_exp = sum(exp_ls)\n",
    "result = [i/sum_exp for i in exp_ls]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.05529145, -3.06733405, -2.34886792, -2.63755817, -2.73216461,\n",
       "       -2.99769353, -2.96916957])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2([0.1203, 0.1193, 0.1963, 0.1607, 0.1505, 0.1252, 0.1277])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(y_true, y_hat):\n",
    "    return np.sum(- np.array(y_true) * np.log2(np.array(y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8703872618695303"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1, 0, 0, 0, 0, 0, 0] \n",
    "y_hat = [0.1203,  0.1193 , 0.1963, 0.1607 , 0.1505 , 0.1252, 0.1277]\n",
    "\n",
    "word_3rd = [0, 0, 0, 1, 0, 0, 0]\n",
    "# I'm adding the already softmaxed value here. \n",
    "# In fact it supposed to be just logits value which is the value before softmax.\n",
    "predicted_3rd = [0.1169, 0.1229, 0.1192, 0.2735, 0.1358, 0.1204, 0.1112]\n",
    "CrossEntropy(word_3rd, predicted_3rd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
